import os
import logging
from datetime import datetime
from flask import Blueprint, render_template, jsonify
import google.generativeai as genai

# âœ… Configure Gemini API with environment variable
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# âœ… Initialize Gemini model (text-only)
model = genai.GenerativeModel("gemini-1.5-flash")

# âœ… Flask Blueprint
dashboard_bp = Blueprint('dashboard', __name__)

# âœ… Persona Prompt (embed as first system message if needed)
MALAYSIAN_ENTREPRENEUR_PROMPT = """
You are Dr. Siti Rahman â€” a Malaysian academic entrepreneur with 15+ years of experience across academia, startup mentoring, and digital innovation.

## ğŸ‘©â€ğŸ« Background:
- Professor of Innovation Management, Universiti Malaya
- PhD from University of Cambridge
- Founder of 3 tech startups in fintech, edtech, and healthtech
- Former researcher at MIER
- Trusted mentor for Malaysian startup programs (MaGIC, Cradle, etc.)

## ğŸ¯ Personality:
- Warm, practical, and encouraging â€” a "Kak Siti" type mentor
- Drops occasional Bahasa Malaysia terms (e.g., â€œboleh lahâ€, â€œsikitâ€, â€œjangan risauâ€)
- Reflective tone: connects advice with personal lessons and past experience
- Mix of academic insight and real-world practicality

## ğŸ—£ï¸ Answer Style Guidelines:
1. Responses should feel personal and empathetic â€” like speaking to a mentee over coffee.
2. Start answers with *greeting* or *encouragement* (â€œJangan risauâ€, â€œIâ€™m glad you asked that!â€).
3. Use vivid examples from Malaysian startups (e.g., "I remember when StoreHub first raised funding...")
4. Be concise (under 70 words) but impactful.
5. Offer *culturally relevant*, *actionable* steps â€” e.g., where to apply, whom to speak to.
6. When appropriate, add light motivational closing lines like â€œYou can do this, insyaAllah.â€

## ğŸ§­ Context Awareness:
Always ground advice in the Malaysian ecosystem â€” mention MDEC, MIDA, grants, Bumiputera policies, or Islamic finance where relevant.

## ğŸ’¡ Tone:
Empathetic big-sister energy + seasoned professor. Youâ€™re smart, but approachable.
"""

# âœ… In-memory store for conversation history
conversation_history = {}

# âœ… Main AI response function using Gemini
def get_ai_response(user_message, phone_number):
    try:
        # Init history
        if phone_number not in conversation_history:
            conversation_history[phone_number] = []

        # Add user input
        conversation_history[phone_number].append({"role": "user", "content": user_message})

        # Build prompt parts in Gemini format
        parts = [{"role": "user", "parts": [MALAYSIAN_ENTREPRENEUR_PROMPT]}]  # Persona prompt as context
        parts += [{"role": "user", "parts": [msg["content"]]} for msg in conversation_history[phone_number]]

        # Get Gemini response
        response = model.generate_content(parts)
        return response.text.strip()

    except Exception as e:
        logging.error(f"Error generating Gemini AI response: {str(e)}")
        return "Maaf, sistem AI sedang menghadapi masalah teknikal. Sila cuba sebentar lagi."

# âœ… Basic dashboard route
@dashboard_bp.route('/')
def dashboard():
    return render_template('dashboard.html')

# âœ… Statistics API
@dashboard_bp.route('/api/stats')
def get_stats():
    try:
        total_conversations = len(conversation_history)
        total_messages = sum(len(conv) for conv in conversation_history.values())
        return jsonify({
            'status': 'active',
            'total_conversations': total_conversations,
            'total_messages': total_messages,
            'last_updated': datetime.now().isoformat()
        })
    except Exception as e:
        logging.error(f"Error getting stats: {str(e)}")
        return jsonify({'error': 'Failed to get statistics'}), 500

# âœ… Recent conversations API
@dashboard_bp.route('/api/conversations')
def get_conversations():
    try:
        recent_conversations = []
        for phone, history in conversation_history.items():
            if history:
                masked_phone = phone[:3] + "*" * (len(phone) - 6) + phone[-3:]
                recent_conversations.append({
                    'phone': masked_phone,
                    'last_message_time': datetime.now().isoformat(),
                    'message_count': len(history)
                })
        return jsonify(recent_conversations[-10:])
    except Exception as e:
        logging.error(f"Error getting conversations: {str(e)}")
        return jsonify({'error': 'Failed to get conversations'}), 500

 
